{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image layer tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the tutorial on the **napari** `Image` layer!\n",
    "\n",
    "This tutorial assumes you have already installed **napari**, know how to launch the viewer, and are familiar with its layout.\n",
    "For help with installation see our [installation](./installation) tutorial.\n",
    "For help getting started with the viewer see our [getting started](./getting_started) tutorial.\n",
    "For help understanding the organisation of the viewer,\n",
    "including things like the layers list,\n",
    "the layer properties widgets,\n",
    "the layer control panels,\n",
    "and the dimension sliders\n",
    "see our [napari viewer](./viewer) tutorial.\n",
    "\n",
    "This tutorial will teach you about the **napari** `Image` layer,\n",
    "including the types of images that can be displayed,\n",
    "and how to set properties like the contrast, opacity, colormaps and blending mode.\n",
    "At the end of the tutorial you should understand how to add and manipulate a variety of different types of images both from the GUI and from the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a simple example\n",
    "\n",
    "You can create a new viewer and add an image in one go using the `napari.view_image` method,\n",
    "or if you already have an existing viewer, you can add an image to it using `viewer.add_image`.\n",
    "The api of both methods is the same.\n",
    "In these examples we'll mainly use `view_image`.\n",
    "\n",
    "A simple example of viewing an image is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt  # we need to start the Qt event loop before importing napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is required for the automated continuous integration\n",
    "# It allows the async Qt magic in the previous cell time to load\n",
    "import time\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from skimage import data\n",
    "\n",
    "cells = data.cells3d()[30, 1]  # grab some data\n",
    "viewer = napari.view_image(cells, colormap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arguments of view_image and add_image\n",
    "\n",
    "\n",
    "Both `view_image` and `add_image` have the following doc strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "napari.view_image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image data and numpy-like arrays\n",
    "\n",
    "napari can take any numpy-like array as input for its image layer.\n",
    "A numpy-like array can just be a [numpy array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html),\n",
    "a [dask array](https://docs.dask.org/en/stable/array.html),\n",
    "an [xarray](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html),\n",
    "a [zarr array](https://zarr.readthedocs.io/en/stable/api/core.html),\n",
    "or any other object that you can index into\n",
    "and when you call [`np.asarray`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.asarray.html) on it you get back a numpy array.\n",
    "\n",
    "The great thing about napari support array-like objects is that you get to keep on using your favorite array libraries\n",
    "without worrying about any conversions as we'll handle all of that for you.\n",
    "\n",
    "napari will also wait until just before it displays data onto the screen to actually generate a numpy array from your data,\n",
    "and so if you're using a library like `dask` or `zarr` that supports lazy loading and lazy evaluation,\n",
    "we won't force you load or compute on data that you're not looking at.\n",
    "This enables napari to seamlessly browse enormous datasets that are loaded in the right way.\n",
    "For example, here we are browsing over 100GB of lattice lightsheet data stored in a zarr file:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image: lattice light sheet microscopy](../assets/tutorials/LLSM.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image pyramids\n",
    "\n",
    "For exceptionally large datasets napari supports image pyramids.\n",
    "An image pyramid is a list of arrays, where each array is downsampling of the previous array in the list,\n",
    "so that you end up with images of successively smaller and smaller shapes.\n",
    "A standard image pyramid might have a 2x downsampling at each level,\n",
    "but napari can support any type of pyramid as long as the shapes are getting smaller each time.\n",
    "\n",
    "Image pyramids are especially useful for incredibly large 2D images when viewed in 2D or incredibly large 3D images when viewed in 3D.\n",
    "For example this ~100k x 200k pixel pathology image consists of 10 pyramid levels\n",
    "and can be easily browsed as at each moment in time\n",
    "we only load the level of the pyramid and the part of the image that needs to be displayed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image: pathology](../assets/tutorials/pathology.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example had precomputed image pyramids stored in a zarr file, which is best for performance.\n",
    "If, however you don't have a precomputed pyramid but try and show a exceptionally large image\n",
    "napari will try and compute pyramids for you unless you tell it not too.\n",
    "\n",
    "You can use the `is_pyramid` keyword argument to specify if your data is an image pyramid or not.\n",
    "If you don't provide this value, then will try and guess whether your data is or needs to be an image pyramid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D rendering of images\n",
    "\n",
    "All our layers can be rendered in both 2D and 3D mode, and one of our viewer buttons can toggle between each mode.\n",
    "The number of dimensions sliders will be 2 or 3 less than the total number of dimensions of the layer,\n",
    "allowing you to browse volumetric timeseries data and other high dimensional data.\n",
    "See for example these cells undergoing mitosis in this volumetric timeseries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image: mitorsis](../assets/tutorials/mitosis.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing rgb vs luminance (grayscale) images\n",
    "\n",
    "In this example we explicitly set the `rgb` keyword to be `True`\n",
    "because we know we are working with an `rgb` image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from skimage import data\n",
    "\n",
    "viewer = napari.view_image(data.astronaut(), rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had left that keyword argument out\n",
    "napari would have successfully guessed that we were trying to show an `rgb` or `rgba` image\n",
    "because the final dimension was 3 or 4.\n",
    "If you have a luminance image where the last dimension is 3 or 4\n",
    "you can set the `rgb` property to `False` so napari handles the image correctly.\n",
    "\n",
    "`rgb` data must either be `uint8`, corresponding to values between 0 and 255, or `float` and between 0 and 1.\n",
    "If the values are `float` and outside the 0 to 1 range they will be clipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working with colormaps\n",
    "\n",
    "napari supports any colormap that is created with `vispy.color.Colormap`.\n",
    "We provide access to some standard colormaps that you can set using a string of their name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These include:\n",
    "- PiYG\n",
    "- blue\n",
    "- cyan\n",
    "- gist_earth\n",
    "- gray\n",
    "- green\n",
    "- hsv\n",
    "- inferno\n",
    "- magma\n",
    "- magenta\n",
    "- plasma\n",
    "- red\n",
    "- turbo\n",
    "- twilight\n",
    "- twilight_shifted\n",
    "- yellow\n",
    "- viridis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing any of these as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data.moon(), colormap='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... will set the colormap of that image.\n",
    "You can also access the current colormap through the `layer.colormap` property\n",
    "which returns a tuple of the colormap name followed by the vispy colormap object.\n",
    "You can list all the available colormaps using `layer.colormaps`.\n",
    "\n",
    "It is also possible to create your own colormaps using vispy's `vispy.color.Colormap` object,\n",
    "see it's full [documentation here](http://vispy.org/color.html#vispy.color.Colormap).\n",
    "Briefly, you can pass `Colormap` a list of length 3 or length 4 lists,\n",
    "corresponding to the `rgb` or `rgba` values at different points along the colormap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to make a diverging colormap that goes from red to blue through black,\n",
    "and color a random array you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from vispy.color import Colormap\n",
    "\n",
    "cmap = Colormap([[1, 0, 0], [0, 0, 0], [0, 0, 1]])\n",
    "image = np.random.random((100, 100))\n",
    "\n",
    "viewer = napari.view_image(image, colormap=('diverging', cmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in this example how we passed the colormap keyword argument as a tuple containing both a name for our new custom colormap and the colormap itself.\n",
    "If we had only passed the colormap it would have been given a default name.\n",
    "\n",
    "The named colormap now appears in the dropdown menu alongside a little thumbnail of the full range of the colormap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjusting contrast limits\n",
    "\n",
    "Each image layer gets mapped through its colormap according to values called contrast limits.\n",
    "The contrast limits are a 2-tuple where the second value is larger than the first.\n",
    "The smaller contrast limit corresponds to the value of the image data that will get mapped to the color defined by 0 in the colormap.\n",
    "All values of image data smaller than this value will also get mapped to this color.\n",
    "The larger contrast limit corresponds to the value of the image data that will get mapped to the color defined by 1 in the colormap.\n",
    "All values of image data larger than this value will also get mapped to this color.\n",
    "\n",
    "For example, you are looking at an image that has values between 0 and 100 with a standard `gray` colormap,\n",
    "and you set the contrast limits to `(20, 75)`.\n",
    "Then all the pixels with values less than 20 will get mapped to black, the color corresponding to 0 in the colormap,\n",
    "and all pixels with values greater than 75 will get mapped to white, the color corresponding to 1 in the colormap.\n",
    "All other pixel values between 20 and 75 will get linearly mapped onto the range of colors between black and white.\n",
    "\n",
    "In napari you can set the contrast limits when creating an `Image` layer\n",
    "or on an existing layer using the `contrast_limits` keyword argument or property, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from skimage import data\n",
    "\n",
    "viewer = napari.view_image(data.moon(), name='moon')\n",
    "viewer.layers['moon'].contrast_limits=(100, 175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the contrast limits are defined by two values\n",
    "the corresponding slider has two handles,\n",
    "one the adjusts the smaller value,\n",
    "one that adjusts the larger value.\n",
    "\n",
    "As of right now adjusting the contras limits has no effect for `rgb` data.\n",
    "\n",
    "If no contrast limits are passed, then napari will compute them.\n",
    "If your data is small, then napari will just take the minimum and maximum values across your entire image.\n",
    "If your data is exceptionally large, this operation can be very time consuming\n",
    "and so if you have passed an image pyramid then napari will just use the top level of that pyramid,\n",
    "or it will use the minimum and maximum values across the top, middle, and bottom slices of your image.\n",
    "In general, if working with big images it is recommended you explicitly set the contrast limits if you can.\n",
    "\n",
    "Currently if you pass contrast limits as a keyword argument to a layer\n",
    "then full extent of the contrast limits range slider will be set to those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer visibility\n",
    "\n",
    "All our layers support a visibility toggle that allows you to set the `visible` property of each layer.\n",
    "This property is located inside the layer widget in the layers list and is represented by an eye icon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer opacity\n",
    "\n",
    "All our layers support an opacity slider and `opacity` property\n",
    "that allow you to adjust the layer opacity between 0, fully invisible and 1, fully visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blending layers\n",
    "\n",
    "All our layers support three blending modes `translucent`, `additive`, and `opaque`\n",
    "that determine how the visuals for this layer get mixed with the visuals from the other layers.\n",
    "\n",
    "An `opaque` layer renders all the other layers below it invisible\n",
    "and will fade to black as you decrease its opacity.\n",
    "\n",
    "The `translucent` setting will cause the layer to blend with the layers below it if you decrease its opacity\n",
    "but will fully block those layers if its opacity is 1.\n",
    "This is a reasonable default, useful for many applications.\n",
    "\n",
    "The final blending mode `additive` will cause the layer to blend with the layers below even when it has full opacity.\n",
    "This mode is especially useful for many cell biology applications\n",
    "where you have multiple different components of a cell labeled in different colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "![image: blending](../assets/tutorials/blending.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer interpolation\n",
    "\n",
    "We support a variety of interpolation modes when viewing 2D slices.\n",
    "In the default mode `nearest` each pixel is represented as a small square of specified size.\n",
    "As you zoom in you will eventually see each pixel.\n",
    "In other modes neighbouring pixels are blended together according to different functions,\n",
    "for example `bicubic`, which can lead to smoother looking images.\n",
    "For most scientific use-cases `nearest` is recommended because it does not introduce more artificial blurring.\n",
    "These modes have no effect when viewing 3D slices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer rendering\n",
    "\n",
    "When viewing 3D slices, we support a variety of rendering modes.\n",
    "The default mode `mip`, or maximum intensity projection,\n",
    "will combine voxels at different distances from the camera according to a maximum intensity projection\n",
    "to create the 2D image that is then displayed on the screen.\n",
    "This mode works well for many biological images such as these cells growing in culture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image: rendering](../assets/tutorials/rendering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When viewing 2D slices the rendering mode has no effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naming layers\n",
    "\n",
    "All our layers support a `name` property that can be set inside a text box inside the layer widget in the layers list.\n",
    "The name of each layer is forced into being unique\n",
    "so that you can use the name to index into `viewer.layers` to retrieve the layer object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling layers\n",
    "\n",
    "All our layers support a `scale` property and keyword argument that will rescale the layer multiplicatively\n",
    "according to the scale values (one for each dimension).\n",
    "This property can be particularly useful for viewing anisotropic volumes\n",
    "where the size of the voxel in the z dimension might be different then the size in the x and y dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translating layers\n",
    "\n",
    "All our layers support a `translate` property and keyword argument\n",
    "that you can use to offset a layer relative to the other layers,\n",
    "which could be useful if you are trying to overlay two layers for image registration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer metadata\n",
    "\n",
    "All our layers also support a `metadata` property and keyword argument\n",
    "that you can use to store an arbitrary metadata dictionary on the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next steps\n",
    "\n",
    "Hopefully, this tutorial has given you a detailed understanding of the `Image` layer,\n",
    "including how to create one and control its properties.\n",
    "To learn more about some of the other layer types that **napari** supports\n",
    "checkout some more of our tutorials listed below.\n",
    "The [labels layer](./labels) tutorial is a great one to try next\n",
    "as labels layers are an extension of our image layers used for labeling regions of images."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
